

** add exercises to part 1.
* add horizontal rules around eercises.

* exercise in part 2  - would you add extra codes, etc. 
* NLP
* profiling
* adding some exercises
* machine learning 
* more exercises
* more readme
* fill out list of modules, etc. in references
* review jupyter on github
** https://help.github.com/articles/working-with-jupyter-notebook-files-on-github/ 
**


---
# DONE
* Verify saved data
* what happens when a tweet is seen multiple times - I don't
  understand it?  ANSWER - this is an artifact of the search results. A tweet can be returned multiple times. filter it out an move on
* test with oop to see if I can read back in from file. - nope. not easily
* iterate through to check load vs. save
* section 4 reads in file..
* figure out why we don't necessarily get tweets in the same order when reading them in.  - revise approach to getting first. 100
  - get keys, sort by id, and then take first 100.
  * redo annotations. tweet 6 onwards
* exercise 3 - additional queries (revising save)
* split into two files
** create an overview with key elements
** remove end from part 1
** remove beginning from part 2 (but add in read/save Tweets)
** add intro to part 2
** add links at end of part 1 to part 2
** add links at beginning of part 2 to part 1
** figure out how to link between them
** check in.
