{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Social Media and Human-Computer Interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  *Goal*: Use social media posts to explore the appplication of text and natural language processing to see what might be learned from online interactions.\n",
    "\n",
    "Specifically, we will retrieve, annotate, process, and interpret Twitter data on health-related issues such as depression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "References:\n",
    "* [Mining Twitter Data with Python (Part 1: Collecting data)](https://marcobonzanini.com/2015/03/02/mining-twitter-data-with-python-part-1/)\n",
    "* The [Tweepy Python API for Twitter](http://www.tweepy.org/)\n",
    "\n",
    "Required Software\n",
    "* [Python 3](https://www.python.org)\n",
    "* [NumPy](http://www.numpy.org) - for preparing data for plotting\n",
    "* [Matplotlib](https://matplotlib.org) - plots and garphs\n",
    "* [jsonpickle](https://jsonpickle.github.io) for storing tweets. \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import jsonpickle\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Analysis of social-media discussions has grown to be an important tool for biomedical informatics researchers, particularly for addressing questions relevant to public perceptions of health and related matters. Studies have examination of a range of topics at the intersection of health and social media, including studies of how [Facebook might be used to commuication health information](http://www.jmir.org/2016/8/e218/) how Tweets might be used to understand how smokers perceive [e-cigarettes, hookahs and other emerging smoking products](https://www.jmir.org/2013/8/e174/), and many others.\n",
    "\n",
    "Although each investigation has unique aspects, studies of social media generally share several common tasks. Data acquisition is often the first challenge: although some data may be freely available, there are often [limits](https://dev.twitter.com/rest/public/rate-limits) as to how much data can be queried easily. Researchers might look out for [opportunities for accessing larger amounts of data](https://www.wired.com/2014/02/twitter-promises-share-secrets-academia/). Some studies contract with [commercial services providing fee-based access](https://gnip.com). \n",
    "\n",
    "Once a data set is hand, the next step is often to identify key terms and phrases relating to the research question. Messages might be annotated to indicate specific categorizations of interest - indicating, for example, if a message referred to a certain aspect of a disease or symptom. Similarly, key words and phrases regularly occurring in the content might also be identified. Natural language and text processing techniques might be used to extract key words, phrases, and relationships, and machine learning tools might be used to build classifiers capable of distinguishing between types of tweets of interest. \n",
    "\n",
    "This module presents a preliminary overview of these techniques, using Python 3 and several auxiliary libraries to explore the application of these techniques to Twitter data. \n",
    "  \n",
    "  1. Configuration of tools to access Twitter data\n",
    "  2. Twitter data retrieval\n",
    "  3. Searching for tweets\n",
    "  4. Annotation of tweets\n",
    "  5. Natural Language Processing\n",
    "  6. Examination of text patterns\n",
    "  7. Construction of classifiers\n",
    "  8. Exercises and next steps\n",
    "  \n",
    "\n",
    "Our case study will apply these topics to Twitter discussions of smoking and tobacco. Although details of the tools used to access data and the format and content of the data may differ for various services, the strategies and procedures used to analyze the data will generalize to other tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration of tools to access Twitter data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "[Twitter](www.twitter.com) provides limited capabilities for searching tweets through an Application Programming Interface (API) based on Representational State Transfer (REST).  [REST](https://doi.org/10.1145/337180.337228) is an approach to using web-based Hypertext-Transfer Protocol (HTTP) requests as APIs. \n",
    "\n",
    "Essentially, a REST API specifies conventions for HTTP requests that might be used to retrieve specific data items from a remote server. Unlike traditional HTTP requests, which return HTML markup to be rendered in web browsers, REST APIs return data formatted in XML or JSON, suitable for interpretation by computer programs. REST APIs from familiar websites underlie frequently-seen functionality such as embedded twitter widgets and \"like/share\" links, among others.\n",
    "\n",
    "Commercial REST applications often use \"API-Keys\" - unique identifiers used to associate requests with registered accounts. Here, we will walk through the process of registering for Twitter API keys and using a Python library to manage the details of making a Twitter API request and receiving a response.\n",
    "\n",
    "1.1 Registering for a Twitter API key\n",
    "\n",
    "1.1.1 *Signup for Twitter* The first step in registering for a Twitter API key is to [signup](https://twitter.com/signup) for an account. If you dont' want to post anything or to use the account in any way that might be linked to your regular email adddress, you might want to create a special-purpose account using a service such as gmail, and use this new email address for the twitter account.\n",
    "\n",
    "1.1.2. *Create a Twitter application*: Go to  [Twitter's developer site](https://dev.twitter.com) and click on \"My Apps\". Click on \"Create New App\" in the upper right and then fill out the form. The main thing that you need to focus on here is the application name, description, and website. The rest can be ignored.\n",
    "\n",
    "Creating the application will lead to the display of some information with some URLs and a few tabs. Look under \"Keys and Access Tokens\" to see the Consumer API key and API Secret - these will come in handy later.\n",
    "\n",
    "There will also be a button that says \"Create my access token\". Press this button and make a note of the Access Token and Access Token Secret values that are displayed. \n",
    "\n",
    "Although hese tokens are always available on the application page, for the purpose of this exercise, it's best to store them in Python variables directly in this Jupyter notebook. Execute the following insstructions, substituting the keys for your application for the phrases \"YOUR-CONSUMER-KEY\", etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "consumer_key = 'YOUR-CONSUMER-KEY'\n",
    "consumer_secret = 'YOUR-CONSUMER-SECRET'\n",
    "access_token = 'YOUR-ACCESS-TOKEN'\n",
    "access_secret = 'YOUR-ACCESS-SECRET'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Note that the following should be redacted*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "consumer_key='D2L4YZ2YrO1PMix7uKUK63b8H'\n",
    "consumer_secret='losRw9T8zb6VT3TEJ9JHmmhAmn1GXKVj30dkiMv9vjhXuiWek9'\n",
    "access_token='15283934-iggs1hiZAPI2o5sfHWMfjumTF7SvytHPjpPRGf3I6'\n",
    "access_secret='bOvqssxS97PGPwXHQZxk83KtAcDyLhRLgdQaokCdVvwFi'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In theory, you know have all that you need to start accessing Twitter. Using these keys and the information in the [Twitter Developer Documentation](https://dev.twitter.com/docs), you might conceivably create web requests to search for tweets, post, and read your timeline. In practice, it's a bit more complicated, so most folks use third-party tools that take care of the hard work. \n",
    "\n",
    "1.1.3 *Try the Tweepy library*: [Tweepy](http://www.tweepy.org) is a Python 3 library for using the Twitter API. Like other similar libraries - there are many for Python and other languages - Tweepy takes care of the details of authorization and provides a few simple function calls for accessing the API.  \n",
    "\n",
    "The first step in using Tweepy is *authorization* - establishing your credentials for using the Twitter API. Tweepy uses the [OAuth](http://www.oauth.net) authorization framework, which is widely used for both API and user access to services provided over HTTP. Fortunately Tweepy hides the oauth details. All you need to do is to make a few calls to the Tweepy library and you're all set to go. Run the following code, making sure that the four variables are set to the values you were given when you registered your Twitter application:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "\n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "api = tweepy.API(auth)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this worked correctly, you should see something like this \n",
    "```\n",
    "<tweepy.api.API at 0x109da36d8>\n",
    "``` \n",
    "\n",
    "If you get an error message, please check your keys and tokens to ensure that they are correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Twitter data retrieval\n",
    "\n",
    "Now that you have successfully accessed the Twitter API, it's time to access the data. The simplest thing to do is to grab some Tweets off of your timeline. Try the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_ten = []\n",
    "i =0\n",
    "for tweet in tweepy.Cursor(api.home_timeline).items(10):\n",
    "    top_ten.append(tweet._json)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several key componnents to this block of code:\n",
    "* ```api.home_timeline``` is a component of the API object, referring to the user timeline - the tweets shown on your home page.\n",
    "* ```tweepy.Cursor``` is a construct in the Tweepy API that supports navigation through a large set of results.\n",
    "* ```tweepy.Cursor(api.home_timeline).items(10)``` essentially asks Tweepy to set up a cursor for the home timeline and then to get the first 10 items in that set. The result is a Python Iterator, which can be used to examine the items in the set in turn.\n",
    "* We will grab the JSON representation of each tweet (stored as \"tweet.\\_json\") for maximum flexibility.\n",
    "* The loop takes each of those objects an adds them into a Python array.\n",
    "\n",
    "Now, each of the items in ```top_ten``` is a Tweet object. Let's take a look inside. We'll start by grabbing the first text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweet1=top_ten[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and looking at its text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweet1['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".. noting that the text is roughly 140 characters long..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(tweet1['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also examine when the tweet was created..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweet1['created_at']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".. whether it has been favorited..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweet1['favorited']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".. The unique ID String of the Tweet..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweet1['id_str']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".. and the name of the Twitter user responsible for the post. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweet1['user']['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweet1=top_ten[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweet1['id_str']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check to see if a tweet is a retweet by seeing if it has the 'retweeted_status' attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'retweeted_status' in tweet1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also see if your tweet was a retweet. If it was, the <em>retweeted_status</em> field will hold information about the original tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "if 'retweeted_status' in tweet1:\n",
    "    original = tweet1['retweeted_status']\n",
    "    print(original['user']['name'])\n",
    "else:\n",
    "    print(\"not a rewteet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The twitter API supports many other details for users, tweets, and other entities. See [The Twitter API Overview](https://dev.twitter.com/overview/api) for general details and subpages about [Tweets](https://dev.twitter.com/overview/api/tweets), [Users](https://dev.twitter.com/overview/api/users) and related pages for specific details of other data types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Searching for tweets\n",
    "\n",
    "Our next major goal will be to search for Tweets. Effective searching requires both construction of useful queries (the hard part) and use of the Tweepy search API (the easy part).\n",
    "\n",
    "### 3.1 Formulating a query\n",
    "\n",
    "Formulating an effective search query is often a challenging, iterative process. Trying some searches in the Twitter web page is a good way to see both how a query might be formulated and which queries might be most useful.\n",
    "\n",
    "If you look carefully at the URL bar in your browser after running a search, you might notice that the search term is embedded in the URL. Thus, if you search for \"depression\", you might see a URL that looks like https://twitter.com/search?q=depression. You might also see \"&src=typed\" at the end of the URL, indicating that the search was typed by hand.\n",
    "\n",
    "You can also use Tweepy to conduct a search, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tlist = api.search(\"smoking\",lang=\"en\",count=10)\n",
    "tweets = [t._json for t in tlist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This search will find the first 10 English tweets matching the term \"depression\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets[0]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then look at the text for these tweets. This is a good way to check to ensure that we're getting what we think we should be getting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "texts = [c['text'] for c in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "You may see some tweets that don't match exactly - perhaps using 'depressed' instead of 'depression'. This suggests that Twitter uses <em>stemming</em> - removing suffixes and variations to get to the core of the word - to increase search accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we should be able to evaluate the results to see if we are on the right track. If we aren't, we'd want to try some different queries. For now, it looks good, so let's move on.\n",
    "\n",
    "### 3.2 Collecting and characterizing a larger corpus\n",
    "\n",
    "Our original query only retrieved 10 tweets. This is a good start, but probably not enough for anything serious. We can loop through several times to create a longer list, with a delay between searches to avoid overstaying our welcome with Twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "for i in range(10):\n",
    "    new_tweets = api.search(\"smoking\",lang=\"en\",count=100)\n",
    "    nt = [t._json for t in new_tweets]\n",
    "    tweets= tweets+nt\n",
    "    time.sleep(5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "At this point, we might want to know something about the tweets that we have retrieved. As our goal is to shoot for linguistic diversity, we want to make sure that we don't have too many retweets, and that we have a wide range of authors. Let's run through the tweets and count the number of authors and retweets. We can count authors in a dictionary and retweets in a simple variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "authors={}\n",
    "retweets=0\n",
    "for t in tweets:\n",
    "    # is it a retweet? If so, increment\n",
    "    if 'retweeted_status' in t:\n",
    "        retweets = retweets+1\n",
    "    # get tweet author name\n",
    "    uname = t['user']['name']\n",
    "    # if not in authors, put it in with zero articles\n",
    "    if uname not in authors:\n",
    "        authors[uname]=0\n",
    "    authors[uname]=authors[uname]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(authors.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might see a lot of retweets here - I saw at least 80% in one instance, with about 193 authors. This suggests that this corpus has a good many authors with multiple tweets. \n",
    "\n",
    "To explore this, let's look at the histogram of the number of tweets/author."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To examine the distribution of authors, we can use the [NumPy](http://www.numpy.org) and [Matplotlib](http://matplotlib.org) libraries to extract the number of tweets from each user (given by authors.values()) and to plot a histogram..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vals = np.array(list(authors.values()))\n",
    "#plt.xticks(range(min(vals),max(vals)+1))\n",
    "plt.hist(vals,np.arange(min(vals)-0.5,max(vals)+1.5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like a broad range of the number of tweets/user, up until roughly tweets, with many users having 10 tweets. This is an intersting pattern, with no immediately obvious interpretation. Understanding the usage patterns might be an intersting area for further work, although larger data sets might be necessary to see meaningful patterns.\n",
    "\n",
    "Given the number of retweets and the frequency of posting by some authors, we might be concnered that we are seeing repeated tweets.  To check this, we will review the  tweet IDs in a manner similar to that  which we used for the authors, to see how many of the tweets are unique. \n",
    "\n",
    "As we do this, we'll create a dictionary that will allow us to retrieve tweets by IDs. Specifically, we will create a new diectionary entitled Each `utweets`. This dictionary will be indexed by the ID string of the tweet. Each element of the dictionary will itself be a dictionary, withe the following contents:\n",
    "\n",
    "* 'tweet' will refer to the full tweet\n",
    "* 'count' contains the number of times it occurs in the dataset. \n",
    "\n",
    "Later, we'll add to this structure. \n",
    "\n",
    "In a more complete program, we might use Object-Oriented programming to wrap the data in a [Python Class](https://docs.python.org/3/tutorial/classes.html), but that would add more complexity that we don't want to get into here. \n",
    "\n",
    "For now, we'll proceed by building up the dictionary of tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "utweets={}\n",
    "for t in tweets:\n",
    "    id = t['id_str']\n",
    "    if id not in utweets:\n",
    "        new_entry={}\n",
    "        new_entry['count']=0\n",
    "        new_entry['tweet']=t\n",
    "        utweets[id]=new_entry\n",
    "        \n",
    "    utweets[id]['count']=utweets[id]['count']+1\n",
    "len(utweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can turn this dictionary into a list of id, count pairs, sort by count, and see which ones were repeated most often."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ps = []\n",
    "for t,entry in utweets.items():\n",
    "    count = entry['count']\n",
    "    ps.append((t,count))  \n",
    "ps.sort(key=lambda x: x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm.. only a small portion of our tweets are unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "float(len(utweets))/float(len(tweets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's take a look at the most common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ps[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, many tweets were seen 10 or more times. Let's take a look at them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    idstr = ps[i][0]\n",
    "    count = ps[i][1]\n",
    "    tweet = utweets[idstr]['tweet']\n",
    "    text= tweet['text']\n",
    "    print(idstr+\" \"+text+\" \"+str(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This leads to a question - how can we generate a large set of unique tweets, so as to ensure diversity of results? Our techniques for checking uniquness provide an answer. We can retrieve tweets, checking as we go to see if we've seen them before, and discaring tweets that are repeats. This will continue until we have a large enough set.\n",
    "\n",
    "To do this, we'll have a structure similar to what we used before: \n",
    "* tweets will be a dictionary, keyed by the id string of the tweet\n",
    "* each entry will include a count of the number of times that tweeet was seen, and the tweet itself\n",
    "\n",
    "This may seem a bit cumbersome, but there's an advantage - if we use a structure like this, it becomes very easy to store it to disk, providing a dataset that can easily be shared and reused.\n",
    "\n",
    "Finally, we can store this in a function, allowing us to re-run the search for a different set of terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def searchTwitter(term,corpus_size):\n",
    "    tweets={}\n",
    "    while (len(tweets) < corpus_size):\n",
    "        new_tweets = api.search(term,lang=\"en\",count=100)\n",
    "        for nt_json in new_tweets:\n",
    "            nt = nt_json._json\n",
    "            if nt['id_str'] not in tweets:\n",
    "                new_entry={}\n",
    "                new_entry['count']=0\n",
    "                new_entry['tweet']=nt\n",
    "                tweets[nt['id_str']]=new_entry\n",
    "            tweets[nt['id_str']]['count'] = tweets[nt['id_str']]['count']+1\n",
    "        # wait to give our twitter account a break..\n",
    "        time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets = searchTwitter(\"smoking\",1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Saving tweets, Loading tweets, and Verifying results\n",
    "\n",
    "Now, we've got a good solid set of tweets to work with. Let's save these tweets to a file, using the [jsonpickle](https://jsonpickle.github.io/) library to convert the strucure into a json file, which we will then write to disk. We'll define a function to do this, as we might want to repeat this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def saveTweets(tweets,filename):\n",
    "    json_data =jsonpickle.encode(tweets)\n",
    "    with open(filename,'w') as f:\n",
    "        json.dump(json_data,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saveTweets(tweets,'tweet.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now that that's done, we can read it in again. Once again, we'll write a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readTweets(filename):\n",
    "    with open(filename,'r') as f:\n",
    "        json_data = json.load(f)\n",
    "    tweets = jsonpickle.decode(json_data)\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's  do some quick checks to confirm that we've got the right data out. Note that in future runs, you can just start here to read in your tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets2 = readTweets('tweet.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(tweets2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets == tweets2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[According to Python documentation](https://docs.python.org/2/reference/expressions.html#id24) dictionaries are equal if the keys and values are equal, so this looks good. To check in more detail, we can look at the keys, using subtraction to indicate set difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets.keys()-tweets2.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To confirm, we might look specifically at some tweets.. we'll  find an ID and grab the structures out of each list, reviewing for comparable values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweet_id=random.choice(list(tweets.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t1 = tweets[tweet_id]\n",
    "t2= tweets2[tweet_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t1['tweet']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t2['tweet']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t1==t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spot checks like this give some confidence that the loaded tweets are identical to the saved tweets. We might also run a slightly more rigorous check by iterating through the list to look for similarities. Since we know that the two dictionaries have identical sets of keys, we can iterate through the keys of one to get entries and compare equalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "errs =[]\n",
    "for id in tweets.keys():\n",
    "    t1 =tweets[id]\n",
    "    t2 = tweets2[id]\n",
    "    if t1 != t2:\n",
    "        errs.append(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "errs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. No errors..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Some final notes\n",
    "Note that we might find that we will want to add additional fields to this file. We can always rewreite the file as needed. Saving the file as is gives us a good record that we can work from, without having to recreate the dataset. For subsequent exercises, you can start from this line, without running any of the prior code.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Annotating Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Open Coding\n",
    "\n",
    "Now that we have a corpus of tweets, what do we want to do with them? Turning a relatively vague notion into a well-defined research question is often a significant challenge, as examination of the data often reveals both shortcomings and unforeseen opportunities.\n",
    "\n",
    "In our case, we are interested in looking at tweets about depression, but we're not quite sure exactly *what* we are looking for. We have a vague notion that we might learn something interesting, but understanding exactly what that is, and what sort of analyses we might need, will require a bit more work.\n",
    "\n",
    "In situations such as this, we might look at some of the data to form some preliminary impressions of the content. Specifically, we can look at indidividual tweets, assigning them to one or more categories - known as *codes* - based on their content.  We can add categories as needed to capture important ideas that we might want to refer back to. This practice - known as *open coding* allows us to begin to make sense of unfamiliar data sets. \n",
    "\n",
    "This sounds much more complicated than it is. For now, let's read some tweets in from a file (using the procedure defined above), and then we can get to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets =readTweets(\"tweet-corpus.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will begin by taking a look at a subset of 100 tweets.  Keep in mind that *tweets* is a dictionary mapping id strings to information about tweets. Each entry in *tweets* is itself a dictionary, with 'count' corresponding to the number of times the tweet was sound, and 'tweet' corresponding to the tweet itself.  We're going to add some categories to that dictionary, but we need to start by getting a smaller set of tweets.\n",
    "\n",
    "To get this list, we'll sort the ids of the tweets and take the first 10 in the list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ids=list(tweets.keys())\n",
    "ids.sort()\n",
    "working=[]\n",
    "for i in range(100):\n",
    "    id = ids[i]\n",
    "    entry = tweets[id]\n",
    "    working.append(entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*working* now has 100 tweets. Let's start with the first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "td = working[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FlTNESS: RT DrugedPosts: \"Wyd after smoking this?\" https://t.co/OnLywTyJ0X'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td['tweet']['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tweet has several interesting charcteristics.\n",
    "1. it is a retweet\n",
    "2. It contains a link. \n",
    "\n",
    "We can model all of these points through relevant annotation. Specifically, we will add two new arrays to each tweet object. 'code' will contain a list of categorical annotations associated with the tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "td['code']=[]\n",
    "td['code'].append('LINK')\n",
    "td['code'].append(\"RETWEET\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can confirm that this is a rewtweet by checking for the `retweeted_status` attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'retweeted_status' in td['tweet']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm. the attribute is not present. Perhaps the user copied the text and added 'RT' without actually retweeting? Something to keep our eyes on for other tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's look at the next tweet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT DrugedPosts: \"Wyd after smoking this?\" https://t.co/PZ3YyYh8WB'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td = working[1]\n",
    "td['tweet']['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice this is similar, but not identical, to the previous tweet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "td['code']=[]\n",
    "td['code'].append('LINK')\n",
    "td['code'].append('RETWEET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'retweeted_status' in td['tweet']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok.. moving on to the third tweet.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @Anzers: #TheBetrayalPapers Video: Part II – In Plain Sight – A National Security Smoking Gun\\nhttps://t.co/rpObdW9GcG'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td = working[2]\n",
    "td['tweet']['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This retweet includes a link, a hashtag reference, and a reference to a `Smoking gun`, suggesting that this is not really a tweet about tobacco, marijuana, or other smoking products. We'll label it `irrelevant`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "td['code']=[]\n",
    "td['code'].append('RETWEET')\n",
    "td['code'].append('LINK')\n",
    "td['code'].append('USERMENTION')\n",
    "td['code'].append('HASHTAG')\n",
    "td['code'].append('IRRELEVANT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'retweeted_status' in td['tweet']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @FootyMemes: This new anti-smoking ad is really powerful... https://t.co/pWHZDLIb7O'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td = working[3]\n",
    "td['tweet']['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we have have a retweet, a link, and something about anti-smoking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "td['code']=[]\n",
    "td['code'].append('RETWEET')\n",
    "td['code'].append('LINK')\n",
    "td['code'].append('ANTI-SMOKING')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'retweeted_status' in td['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@ericschmidt @jwnichls Stop. You need to stop torturing me. No buddy nobody cares about \"smoking.\" Stop.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td = working[4]\n",
    "td['tweet']['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This retweet includes user mentions. It might or might not be relevant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "td['code']=[]\n",
    "td['code'].append(\"USERMENTION\")\n",
    "td['code'].append(\"FRUSTRATION\")\n",
    "td['code'].append(\"POSSIBLYRELEVANT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @FurnyFootball: Stop smoking 😂 https://t.co/bY1ZvJy63Z'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td = working[5]\n",
    "td['tweet']['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A retweet with a user mention, and anti-smoking message, and a link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "td['code']=[]\n",
    "td['code'].append(\"RETWEET\")\n",
    "td['code'].append(\"USERMENTION\")\n",
    "td['code'].append(\"ANTI-SMOKING\")\n",
    "td['code'].append(\"LINK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You ever wake up and wish you was still sleep? ... that’s me rn.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td = working[6]\n",
    "td['tweet']['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tweet doesn't seem to be about smoking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "td['code']=[]\n",
    "td['code'].append(\"IRRELEVANT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Resorted to...\". Hahahaha..!  Way to be strong and brave unaided...!  Hahahaha...!  https://t.co/Lnd9N3zBCY via @YahooNews'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td = working[7]\n",
    "td['tweet']['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tweet includes a user mention, and a link, but doesn't seem to be relevant to smoking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "td['code']=[]\n",
    "td['code'].append(\"USERMENTION\")\n",
    "td['code'].append(\"LINK\")\n",
    "td['code'].append(\"IRRELEVANT\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @chocoo_loco: I just want my friends to stop smoking weed😂 https://t.co/LWI2HVofAf'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td = working[8]\n",
    "td['tweet']['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a retweet with a link, a user mention, and an expression of a desire that the user's friends top smoking marijuana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "td['code']=[]\n",
    "td['code'].append(\"RETWEET\")\n",
    "td['code'].append(\"USERMENTION\")\n",
    "td['code'].append(\"LINK\")\n",
    "td['code'].append(\"ANTI-SMOKING\")\n",
    "td['code'].append(\"MARIJUANA\")\n",
    "td['code'].append(\"FRIENDS\")\n",
    "td['code'].append(\"SENTIMENT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and so it goes. You might have to code 100 or more tweets to get a good distribution.\n",
    "\n",
    "## EXERCISE 1: Code the Next 50 tweets in the set. \n",
    "Start with the tags used above, adding your own as needed.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "### answer\n",
    "Following lines to be deleted when provided for student use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No kidding... https://t.co/3Kg2HkfRsc'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td = working[9]\n",
    "td['tweet']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "td['code']=[]\n",
    "td['code'].append(\"LINK\")\n",
    "td['code'].append(\"IRRELEVANT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @xancaps: smoking by myself now\\n\\ni don’t need nobody else around'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td = working[10]\n",
    "td['tweet']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "td['code']=[]\n",
    "td['code'].append(\"RETWEET\")\n",
    "td['code'].append(\"USERMENTION\")\n",
    "td['code'].append(\"HABITS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @GiveMeInternet: Anti smoking ads should show the benefits of quitting instead of the harms of smoking.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td = working[11]\n",
    "td['tweet']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "td['code']=[]\n",
    "td['code'].append(\"RETWEET\")\n",
    "td['code'].append(\"USERMENTION\")\n",
    "td['code'].append(\"ANTI-SMOKING\")\n",
    "td['code'].append(\"QUITTING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@Austin_Sosbee See I have recently started to dream again, Why again? Cause smoking alot of weed stops dreaming, I miss not dreaming lol'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td = working[12]\n",
    "td['tweet']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "td['code']=[]\n",
    "td['code'].append(\"RETWEET\")\n",
    "td['code'].append(\"USERMENTION\")\n",
    "td['code'].append(\"MARIJUNA\")\n",
    "td['code'].append(\"BENEFITS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @FootyMemes: This new anti-smoking ad is really powerful... https://t.co/pWHZDLIb7O'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td = working[13]\n",
    "td['tweet']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "td['code']=[]\n",
    "td['code'].append(\"RETWEET\")\n",
    "td['code'].append(\"USERMENTION\")\n",
    "td['code'].append(\"LINK\")\n",
    "td['code'].append(\"ANTI-SMOKING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @GiveMeInternet: Anti smoking ads should show the benefits of quitting instead of the harms of smoking.'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td = working[14]\n",
    "td['tweet']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "td['code']=[]\n",
    "td['code'].append(\"RETWEET\")\n",
    "td['code'].append(\"USERMENTION\")\n",
    "td['code'].append(\"ANTI-SMOKING\")\n",
    "td['code'].append(\"QUITTING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Mngxitama and his nyaope smoking buddies were a no show today because the Guptas aren't targeted hahahaha\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td = working[15]\n",
    "td['tweet']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "td['code']=[]\n",
    "td['code'].append(\"FRIENDS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @_youngkingdave: Smoking #doinks with @WakaFlocka\\n#doinksquad https://t.co/zex6zRw4Xx'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td = working[16]\n",
    "td['tweet']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "td['code']=[]\n",
    "td['code'].append(\"RETWEET\")\n",
    "td['code'].append(\"USERMENTION\")\n",
    "td['code'].append(\"LINK\")\n",
    "td['code'].append(\"MARIJUNA\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @OnlyWayIsShawtz: My boy stopped smoking weed the day he spent 30 minutes looking for his phone under the bed.. While using his phone fl…'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td = working[17]\n",
    "td['tweet']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "td['code']=[]\n",
    "td['code'].append(\"RETWEET\")\n",
    "td['code'].append(\"USERMENTION\")\n",
    "td['code'].append(\"MARIJUNA\")\n",
    "td['code'].append(\"IMPACT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @GiveMeInternet: Anti smoking ads should show the benefits of quitting instead of the harms of smoking.'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td = working[18]\n",
    "td['tweet']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "td['code']=[]\n",
    "td['code'].append(\"RETWEET\")\n",
    "td['code'].append(\"USERMENTION\")\n",
    "td['code'].append(\"ANTI-SMOKING\")\n",
    "td['code'].append(\"QUITTING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i @KattyKayBBC 'Cannabis is a gateway 2 taking Heroin' were did u hear that pish? Joint smoking 1 day next injecting in2 souls of feet no-no\""
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td = working[19]\n",
    "td['tweet']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "td['code']=[]\n",
    "td['code'].append(\"USERMENTION\")\n",
    "td['code'].append(\"MARIJUNA\")\n",
    "td['code'].append(\"OPIATES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"https://t.co/qchtcveqkA is the world's 1st Smoking Model directory. Search for your favorite… https://t.co/21OlmjWv7Z\""
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td = working[20]\n",
    "td['tweet']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "td['code']=[]\n",
    "td['code'].append(\"LINK\")\n",
    "td['code'].append(\"IRRELEVANT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Additional categories\n",
    "\n",
    "The tweets annotated above are all based on searches for 'smoking'. What if you were to try other terms, such as 'tobacco' or 'vaping'? \n",
    "\n",
    "1. Using the `searchTwitter` procedure defined above, run a search for a set of tweets with one of the these alternative terms.\n",
    "\n",
    "2. Revise `saveTweets` and `readTweets` to store the new set of tweets in a json file, along with the original tweets. How might you distinguish between the two sets? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Summarizing and exploring coding categories\n",
    "\n",
    "Once we have a good set of categories, we can iterate over the tweets and create a dictionary mapping codes to relevant tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "codeDict={}\n",
    "for id,entry in tweets.items():\n",
    "    # for every tweet, look to see if we have any codes\n",
    "    if 'code' in entry:\n",
    "        # for each code\n",
    "        for code in entry['code']:\n",
    "            # look for it in the codeDictionary, creating a new list of codes if needed\n",
    "            if code not in codeDict:\n",
    "                codeDict[code]=[]\n",
    "            # add the id to the dictionary \n",
    "            codeDict[code].append(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "codeDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
